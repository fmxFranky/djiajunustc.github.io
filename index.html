<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
    <link rel="shortcut icon" href="myIcon.ico">
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="keywords" content="Jiajun Deng, The University of Adelaide">
    <meta name="description" content="Jiajun Deng's home page">
    <link rel="stylesheet" href="jemdoc.css" type="text/css" />
    <title>Jiajun Deng</title>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-39824124-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script');
        ga.type = 'text/javascript';
        ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(ga, s);
    })();
    </script>
</head>

<body>
<div id="layout-content" style="margin-top:25px">
<table>
    <tbody>
        <tr>
        	<td width="670">
                <div id="toptitle">
                    <h1 style="color:black;">Jiajun Deng 邓家俊</h1>
				</div>
				<h3 style="color:black;">
					Research Fellow </br>
				</h3>
				<p>
					<!-- Room 610, Teaching Complex C </br> -->
					Australian Institute for Machine Learning </br>
					The University of Adelaide </br>
					Adelaide, SA, Australia</br>
					</br>
					Email: <a href="djiajun1206@gmail.com">djiajun1206 [at] gmail [dot] com</a>
				</p>
				<p>
					<a href='https://scholar.google.com/citations?user=FAAHjxsAAAAJ'>[Google Scholar]</a> 
					<a href='https://github.com/djiajunustc'>[Github]</a>
					<!-- <a href="https://github.com/djiajunustc"><img src="pics/github.png" height="30px"></a>
					<a href="https://scholar.google.com/citations?user=FAAHjxsAAAAJ"><img src="pics/google_scholar.png" height="30px"></a> -->
					<!-- <a href=""><img src="pics/linkedin.png" height="30px"></a> -->
				</p>
			</td>
			<td><img src="pics/Jiajun_Deng.jpg" border="0" height="220"></br></td>
		<tr>
	</tbody>
</table>

<h2>Biography</h2>
<p>
	<div style="text-align:justify">
		I am a research fellow at The University of Adelaide, working with <a href="https://cs.adelaide.edu.au/~ianr/index.php" target="_blank">Prof. Ian Reid</a>. Previously, I was a postdoctoral researcher at The University of Sydney, working with <a href="https://wlouyang.github.io/" target="_blank">Prof. Wanli Ouyang</a>. I obtained both my Ph.D. degree (2021) and Bachelor's degree (2016) in the Department of Electronic Engineering and Information Science, University of Science and Technology of China (USTC). My Ph.D. advisors are <a href="http://staff.ustc.edu.cn/~lihq/" target="_blank">Prof. Houqiang Li</a> and <a href="http://staff.ustc.edu.cn/~zhwg/" target="_blank">Prof. Wengang Zhou</a>. I have closely cooperated with <a href="http://staff.ustc.edu.cn/~yanyongz/" target="_blank">Prof. Yanyong Zhang</a>. whom I also regarded as my advisor.
	</div>
</p>

<p>My research interests include computer vision and robotics. My current research focuses on 3D understanding & reconstruction, (2D & 3D) vision and language, autonomous intelligent systems (e.g., self-driving vehicles & embodied AI). </p>

<h2>News</h2>
<ul>
	<li>
		<p style="margin-top:3px">
			[2025/05] Two papers accepted by IJCAI 2025 (One for 3D MLLM and the other for weakly-supervised object detection).
		</p>
	</li>
	
	<li>
		<p style="margin-top:3px">
			[2025/04] One paper accepted by IJCV (This paper targets document image rectification). 
		</p>
	</li>

	<li>
		<p style="margin-top:3px">
			[2025/03] Our ACM MM workshop proposal of "Multimodal Foundation Models for Spatial Intelligence" is accepted. Please check 
			<a href="https://sites.google.com/view/mm25-spatial/home" target="_blank" style="font-weight: bold; text-decoration: underline;">here</a> 
			for more information and do not hesitate to submit your papers.
		</p>
	</li>
	

	<li>
		<p style="margin-top:3px">
			[2025/02] I will serve as the area chair of ACM MM 2025.
		</p>
	</li>

	<li>
		<p style="margin-top:3px">
			[2025/02] Two papers accepted by CVPR 2025 (One for 3D MLLM and the other for camera-radar 3D object detection).
		</p>
	</li>

	<li>
		<p style="margin-top:3px">
			[2025/02] One paper accepted by IJCV (This paper explores 3D action recognition).
		</p>
	</li>

</ul>


<h2>Preprint</h2>
<ul>
	* indicates equal contribution; † indicates corresponding author.

	<li>
		<a href="https://arxiv.org/pdf/2403.09212">PoIFusion: Multi-Modal 3D Object Detection via Fusion at Points of Interest</a><br>
		<b>Jiajun Deng</b>, Sha Zhang, Feras Dayoub, Wanli Ouyang, Yanyong Zhang, Ian Reid.<br>
		<!-- <b>Jiajun Deng</b>, Tianyu He, Li Jiang, Tianyu Wang, Feras Dayoub, Ian Reid.<br> -->
		<!-- <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2025.<br> -->
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2403.09212">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2503.16013">GraspCoT: Integrating Physical Property Reasoning for 6-DoF Grasping under Flexible Language Instructions</a><br>
		Xiaomeng Chu, <b>Jiajun Deng†</b>, Guoliang You, Wei Liu, Xingchen Li, Jianmin Ji, Yanyong Zhang†.<br>
		<!-- <b>Jiajun Deng</b>, Tianyu He, Li Jiang, Tianyu Wang, Feras Dayoub, Ian Reid.<br> -->
		<!-- <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2025.<br> -->
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2503.16013">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2503.08217">S3R-GS: Streamlining the Pipeline for Large-Scale Street Scene Reconstruction</a><br>
		Guangting Zheng*, <b>Jiajun Deng*</b>, Xiaomeng Chu, Yu Yuan, Houqiang Li, Yanyong Zhang.<br>
		<!-- <b>Jiajun Deng</b>, Tianyu He, Li Jiang, Tianyu Wang, Feras Dayoub, Ian Reid.<br> -->
		<!-- <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2025.<br> -->
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2503.08217">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2301.05711">OA-BEV: Bringing Object Awareness to Bird's-Eye-View Representation for Multi-Camera 3D Object Detection</a><br>
		Xiaomeng Chu, <b>Jiajun Deng†</b>, Yuan Zhao, Jianmin Ji, Yu Zhang, Houqiang Li, Yanyong Zhang†.<br>
		<!-- <b>Jiajun Deng</b>, Tianyu He, Li Jiang, Tianyu Wang, Feras Dayoub, Ian Reid.<br> -->
		<!-- <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2025.<br> -->
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2301.05711">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

</ul>


<h2>Selected Publications</h2>
<ul>
	* indicates equal contribution; † indicates corresponding author.
	<!-- <li>
		<a href=""></a><br>
		.<br>
		<em></em> <br>
		<p style="margin-top:3px">
			[<a href="">Paper</a>]
			[<a href="">Code</a>]
			[<a href="">Bib</a>]
		</p>
	</li> -->
	<li>
		<a href="https://arxiv.org/pdf/2501.01163">3D-LLaVA: Towards Generalist 3D LMMs with Omni Superpoint Transformer</a><br>
		<b>Jiajun Deng</b>, Tianyu He, Li Jiang, Tianyu Wang, Feras Dayoub, Ian Reid.<br>
		<em>IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2025.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2501.01163">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>
	
	<li>
		<a href="https://arxiv.org/pdf/2412.12725">RaCFormer: Towards High-Quality 3D Object Detection via Query-based Radar-Camera Fusion</a><br>
		Xiaomeng Chu, <b>Jiajun Deng†</b>, Guoliang You, Yifan Duan, Houqiang Li, Yanyong Zhang†.<br>
		<em>IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2025.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2412.12725">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2310.15568"> I2MD: 3D Action Representation Learning with Inter-and Intra-Modal Mutual Distillation</a><br>
		Yunyao Mao*, <b>Jiajun Deng*</b>, Wengang Zhou, Zhenbo Lu, Wanli Ouyang, Houqiang Li.<br>
		<em>International Journal of Computer Vision</em> (<b>IJCV</b>), 2025.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2310.15568">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>


	<li>
		<a href="https://arxiv.org/pdf/2407.02077"> Hierarchical Temporal Context Learning for Camera-based Semantic Scene Completion</a><br>
		Bohan Li, <b>Jiajun Deng</b>, Wenyao Zhang, Zhujin Liang, Dalong Du, Xin Jin, Wenjun Zeng.<br>
		<em>European Conference on Computer Vision</em> (<b>ECCV</b>), 2024.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2407.02077">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2403.11835"> Agent3D-Zero: An Agent for Zero-shot 3D Understanding</a><br>
		Sha Zhang, Di Huang, <b>Jiajun Deng†</b>, Shixiang Tang, Wanli Ouyang, Tong He†, Yanyong Zhang†.<br>
		<em>European Conference on Computer Vision</em> (<b>ECCV</b>), 2024.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2403.11835">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2403.11817"> Hvdistill: Transferring Knowledge from Images to Point Clouds via Unsupervised Hybrid-View Distillation</a><br>
		Sha Zhang, <b>Jiajun Deng†</b>, Lei Bai, Houqiang Li, Wanli Ouyang, Yanyong Zhang†.<br>
		<em>International Journal of Computer Vision</em> (<b>IJCV</b>), 2024.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2403.11817">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2407.14923"> RayFormer: Improving Query-Based Multi-Camera 3D Object Detection via Ray-Centric Strategies</a><br>
		Xiaomeng Chu, <b>Jiajun Deng†</b>, Guoliang You, Yifan Duan, Yao Li, Yanyong Zhang†.<br>
		<em>ACM Multimedia</em> (<b>ACM MM</b>), 2024.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2407.14923">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://openreview.net/pdf?id=Dj6dKnqPU8">FARFusion V2: A Geometry-based Radar-Camera Fusion Method on the Ground for Roadside Far-Range 3D Object Detection</a><br>
		Yao Li, <b>Jiajun Deng</b>, Yuxuan Xiao, Yingjie Wang, Xiaomeng Chu, Jianmin Ji, Yanyong Zhang.<br>
		<em>ACM Multimedia</em> (<b>ACM MM</b>), 2024.<br>
		<p style="margin-top:3px">
			[<a href="https://openreview.net/pdf?id=Dj6dKnqPU8">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2312.15162">Cycle-Consistency Learning for Captioning and Grounding</a><br>
		Ning Wang, <b>Jiajun Deng</b>, Mingbo Jia.<br>
		<em>AAAI Conference on Artificial Intelligence</em> (<b>AAAI</b>), 2024.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2312.15162">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2206.06619">Transvg++: End-to-end Visual Grounding with Language Conditioned Vision Transformer</a><br>
		<b>Jiajun Deng</b>, Zhengyuan Yang, Daqing Liu, Tianlang Chen, Wengang Zhou, Yanyong Zhang, Houqiang Li, Wanli Ouyang.<br>
		<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (<b>TPAMI</b>), 2023.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2206.06619">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/7f2fc4053a66edfa430bcdf9a6ff3b17-Paper-Conference.pdf">CluB: Cluster Meets BEV for LiDAR-based 3D Object Detection</a><br>
		Yingjie Wang, <b>Jiajun Deng†</b>, Yuenan Hou, Yao Li, Yu Zhang, Jianmin Ji, Wanli Ouyang, Yanyong Zhang†.<br>
		<em>Advances in Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2023.<br>
		<p style="margin-top:3px">
			[<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/7f2fc4053a66edfa430bcdf9a6ff3b17-Paper-Conference.pdf">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/8fd5bc08e744fe0dfe798c61d1575a22-Paper-Conference.pdf">CLIP4HOI: Towards Adapting CLIP for Practical Zero-Shot HOI Detection</a><br>
		Yunyao Mao, <b>Jiajun Deng</b>, Wengang Zhou, Li Li, Yao Fang, Houqiang Li.<br>
		<em>Advances in Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2023.<br>
		<p style="margin-top:3px">
			[<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/8fd5bc08e744fe0dfe798c61d1575a22-Paper-Conference.pdf">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Shu_3DPPE_3D_Point_Positional_Encoding_for_Transformer-based_Multi-Camera_3D_Object_ICCV_2023_paper.pdf">3DPPE: 3D Point Positional Encoding for Transformer-based Multi-Camera 3D Object Detection</a><br>
		Changyong Shu*,  <b>Jiajun Deng*</b>, Yifan Liu.<br>
		<em>IEEE/CVF International Conference on Computer Vision</em> (<b>ICCV</b>), 2023.<br>
		<p style="margin-top:3px">
			[<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Shu_3DPPE_3D_Point_Positional_Encoding_for_Transformer-based_Multi-Camera_3D_Object_ICCV_2023_paper.pdf">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="http://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Invariant_Training_2D-3D_Joint_Hard_Samples_for_Few-Shot_Point_Cloud_ICCV_2023_paper.pdf">Invariant Training 2D-3D Joint Hard Samples for Few-Shot Point Cloud Recognition</a><br>
		Xuanyu Yi, <b>Jiajun Deng</b>, Qianru Sun, Xian-Sheng Hua, Joo-Hwee Lim, Hanwang Zhang.<br>
		<em>IEEE/CVF International Conference on Computer Vision</em> (<b>ICCV</b>), 2023.<br>
		<p style="margin-top:3px">
			[<a href="http://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Invariant_Training_2D-3D_Joint_Hard_Samples_for_Few-Shot_Point_Cloud_ICCV_2023_paper.pdf">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>


	<li>
		<a href="http://openaccess.thecvf.com/content/ICCV2023/papers/Mao_Masked_Motion_Predictors_are_Strong_3D_Action_Representation_Learners_ICCV_2023_paper.pdf">Masked Motion Predictors are Strong 3D Action Representation Learners</a><br>
		Yunyao Mao, <b>Jiajun Deng</b>, Wengang Zhou, Yao Fang, Wanli Ouyang, Houqiang Li.<br>
		<em>IEEE/CVF International Conference on Computer Vision</em> (<b>ICCV</b>), 2023.<br>
		<p style="margin-top:3px">
			[<a href="http://openaccess.thecvf.com/content/ICCV2023/papers/Mao_Masked_Motion_Predictors_are_Strong_3D_Action_Representation_Learners_ICCV_2023_paper.pdf">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="http://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Cyclic-Bootstrap_Labeling_for_Weakly_Supervised_Object_Detection_ICCV_2023_paper.pdf">Cyclic-Bootstrap Labeling for Weakly Supervised Object Detection</a><br>
		Yufei Yin, <b>Jiajun Deng</b>, Wengang Zhou, Li Li, Houqiang Li.<br>
		<em>IEEE/CVF International Conference on Computer Vision</em> (<b>ICCV</b>), 2023.<br>
		<p style="margin-top:3px">
			[<a href="http://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Cyclic-Bootstrap_Labeling_for_Weakly_Supervised_Object_Detection_ICCV_2023_paper.pdf">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>


	<li>
		<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Bi-LRFusion_Bi-Directional_LiDAR-Radar_Fusion_for_3D_Dynamic_Object_Detection_CVPR_2023_paper.pdf">Bi-lrfusion: Bi-Directional Lidar-Radar Fusion for 3D Dynamic Object Detection</a><br>
		Yingjie Wang, <b>Jiajun Deng†</b>, Yao Li, Jinshui Hu, Cong Liu, Yu Zhang, Jianmin Ji, Wanli Ouyang, Yanyong Zhang†.<br>
		<em>IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2023.<br>
		<p style="margin-top:3px">
			[<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Bi-LRFusion_Bi-Directional_LiDAR-Radar_Fusion_for_3D_Dynamic_Object_Detection_CVPR_2023_paper.pdf">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/abs/2102.00463">PV-RCNN++: Point-Voxel Feature Set Abstraction With Local Vector Representation for 3D Object Detection</a><br>
		Shaoshuai Shi, Li Jiang, <b>Jiajun Deng</b>, Zhe Wang, Chaoxu Guo, Jianping Shi, Xiaogang Wang, Hongsheng Li.<br>
		<em>International Journal of Computer Vision</em> (<b>IJCV</b>), 2023. <br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2102.00463">Paper</a>]
			<!-- [<a href="https://github.com/open-mmlab/OpenPCDet">Code</a>] -->
			[<a href="papers/ijcv22_pv_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://libkey.io/libraries/44/openurl?sid=google&auinit=Y&aulast=Li&atitle=%24%7B%5Cmathsf+%7BEZFusion%7D%7D+%24:+A+Close+Look+at+the+Integration+of+LiDAR,+Millimeter-Wave+Radar,+and+Camera+for+Accurate+3D+Object+Detection+and+Tracking&id=doi:10.1109/LRA.2022.3193465&title=IEEE+robotics+and+automation+letters&volume=7&issue=4&date=2022&spage=11182&issn=2377-3766">EZFusion: A Close Look at the Integration of LiDAR, Millimeter-Wave Radar, and Camera for Accurate 3D Object Detection and Tracking</a><br>
		Yao Li, <b>Jiajun Deng</b>, Yu Zhang, Jianmin Ji, Houqiang Li, Yanyong Zhang.<br>
		<em>IEEE Robotics and Automation Letters</em> (<b>RAL</b>), 2022.<br>
		<p style="margin-top:3px">
			[<a href="https://libkey.io/libraries/44/openurl?sid=google&auinit=Y&aulast=Li&atitle=%24%7B%5Cmathsf+%7BEZFusion%7D%7D+%24:+A+Close+Look+at+the+Integration+of+LiDAR,+Millimeter-Wave+Radar,+and+Camera+for+Accurate+3D+Object+Detection+and+Tracking&id=doi:10.1109/LRA.2022.3193465&title=IEEE+robotics+and+automation+letters&volume=7&issue=4&date=2022&spage=11182&issn=2377-3766">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2111.14382">VPFNet: Improving 3D Object Detection with Virtual Point based LiDAR and Stereo Data Fusion</a><br>
		Hanqi Zhu, <b>Jiajun Deng</b>, Yu Zhang, Jianmin Ji, Qiuyu Mao, Houqiang Li, Yanyong Zhang.<br>
		<em>IEEE Transactions on Multimedia</em> (<b>TMM</b>), 2022.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2111.14382">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Deng_TransVG_End-to-End_Visual_Grounding_With_Transformers_ICCV_2021_paper.pdf">Transvg: End-to-end Visual Grounding with Transformers</a><br>
		<b>Jiajun Deng</b>,  Zhengyuan Yang, Tianlang Chen, Wengang Zhou, Houqiang Li.<br>
		<em>IEEE/CVF International Conference on Computer Vision</em> (<b>ICCV</b>), 2021.<br>
		<p style="margin-top:3px">
			[<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Deng_TransVG_End-to-End_Visual_Grounding_With_Transformers_ICCV_2021_paper.pdf">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2012.15712">Voxel R-CNN: Towards High Performance Voxel-based 3D Object Detection</a><br>
		<b>Jiajun Deng</b>, Shaoshuai Shi, Peiwei Li, Wengang Zhou, Yanyong Zhang, Houqiang Li.<br>
		<em>AAAI Conference on Artificial Intelligence</em> (<b>AAAI</b>), 2021.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2012.15712">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://ieeexplore.ieee.org/abstract/document/9502540">MINet: Meta-Learning Instance Identifiers for Video Object Detection</a><br>
		<b>Jiajun Deng</b>, Yingwei Pan, Ting Yao, Wengang Zhou, Houqiang Li, Tao Mei.<br>
		<em>IEEE Transactions on Image Processing</em> (<b>TIP</b>), 2021.<br>
		<p style="margin-top:3px">
			[<a href="https://ieeexplore.ieee.org/abstract/document/9502540">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>


	<li>
		<a href="https://arxiv.org/pdf/2107.14391">From Multi-View to Hollow-3D: Hallucinated Hollow-3D R-CNN for 3D Object Detection</a><br>
		<b>Jiajun Deng</b>, Wengang Zhou, Yanyong Zhang, Houqiang Li.<br>
		<em>IEEE Transactions on Circuits and Systems for Video Technology </em> (<b>TCSVT</b>), 2021.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2107.14391">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2106.16136">Weakly Supervised Temporal Adjacent Network for Language Grounding</a><br>
		Yuechen Wang, <b>Jiajun Deng</b>, Wengang Zhou, Houqiang Li.<br>
		<em>IEEE Transactions on Multimedia </em> (<b>TMM</b>), 2021.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2106.16136">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2106.16136">Weakly Supervised Temporal Adjacent Network for Language Grounding</a><br>
		Yuechen Wang, <b>Jiajun Deng</b>, Wengang Zhou, Houqiang Li.<br>
		<em>IEEE Transactions on Multimedia </em> (<b>TMM</b>), 2021.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2106.16136">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>
	
	<li>
		<a href="https://arxiv.org/pdf/2003.03669">Adaptive Offline Quintuplet Loss for Image-Text Matching</a><br>
		Tianlang Chen, <b>Jiajun Deng</b>, Jiebo Luo.<br>
		<em>European Conference on Computer Vision </em> (<b>ECCV</b>), 2020.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2003.03669">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2003.03669">Adaptive offline quintuplet loss for image-text matching</a><br>
		Tianlang Chen, <b>Jiajun Deng</b>, Jiebo Luo.<br>
		<em>European Conference on Computer Vision </em> (<b>ECCV</b>), 2020.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2003.03669">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2007.03560">Single Shot Video Object Detector</a><br>
		<b>Jiajun Deng</b>, Yingwei Pan, Ting Yao, Wengang Zhou, Houqiang Li, Tao Mei.<br>
		<em>IEEE Transactions on Multimedia </em> (<b>TMM</b>), 2020.<br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2007.03560">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

	<li>
		<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Deng_Relation_Distillation_Networks_for_Video_Object_Detection_ICCV_2019_paper.pdf">Relation Distillation Networks for Video Object Detection</a><br>
		<b>Jiajun Deng</b>, Yingwei Pan, Ting Yao, Wengang Zhou, Houqiang Li, Tao Mei.<br>
		<em>IEEE/CVF International Conference on Computer Vision</em> (<b>ICCV</b>), 2019.<br>
		<p style="margin-top:3px">
			[<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Deng_Relation_Distillation_Networks_for_Video_Object_Detection_ICCV_2019_paper.pdf">Paper</a>]
			<!-- [<a href="">Code</a>] -->
			[<a href="papers/cvpr25_3dllava_bib.txt">Bib</a>]
		</p>
	</li>

</ul>

<!-- <h2>Experience</h2>
<ul>
	<li>
		<div style="float:left; text-align:left"><a href="https://www.ox.ac.uk/">Oxford University</a>, Oxford, England</div> <div style="float:right; text-align:right">Jan 2021 – Jul 2021</div><br>
		Visitor (Remote)<br>
		Advisor: <a href="https://hszhao.github.io/">Hengshuang Zhao</a> and <a href="">Philip Torr</a><br>
		Topic: Hand Parsing and Reconstruction<br>
	</li>
	<li>
		<div style="float:left; text-align:left"><a href="https://smartmore.global/">SmartMore</a>, Shenzhen, China</div> <div style="float:right; text-align:right">Feb 2020 – Jul 2021</div><br>
		Computer Vision Research Intern<br>
		Advisor: <a href="http://shuliu.me/">Shu Liu</a><br>
		Topic: 3D Scene Understanding, Robotic Grasping<br>
	</li>
	<li>
		<div style="float:left; text-align:left"><a href="https://www.tencent.com/en-us/">Tencent YouTu Lab</a>, Shenzhen, China</div> <div style="float:right; text-align:right">Jul 2018 – Jan 2020</div><br>
		Computer Vision Research Intern<br>
		Advisor: <a href="http://shuliu.me/">Shu Liu</a> and <a href="">Xiaoyong Shen</a><br>
		Topic: 3D Semantic Segmentation, Depth Prediction<br>
	</li>
	<li>
		<div style="float:left; text-align:left"><a href="https://www.anu.edu.au/">Australian National University (ANU)</a>, Canberra, Australia</div> <div style="float:right; text-align:right">Jul 2016 - Dec 2016</div><br>
		Exchange Student<br>
		Topic: Document Analysis<br>
	</li>
</ul> -->

<h2>Professional Activities</h2>
<ul>
	<li>Guest Editor:<br>
		&emsp; The Special Issue on Pre-trained Models for Multi-modality Understanding, IEEE Transactions on Multimedia (TMM).<br> 
	<li>Area Chair:<br>
		&emsp; ACM Multimedia (ACM MM) 2024, 2025.<br>
		&emsp; IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2025.<br>
	<li>Workshop Organizer:<br>
		&emsp; The 1st International Workshop on Multimodal Foundation Models for Spatial Intelligence, ACM MM 2025.<br>
	<li>Conference Reviewer:<br>
		&emsp; International Conference on Machine Learning (ICML).<br>
		&emsp; IEEE Conference on Computer Vision and Pattern Recognition (CVPR).<br>
		&emsp; IEEE International Conference on Computer Vision (ICCV).<br>
		&emsp; European Conference on Computer Vision (ECCV).<br>
		&emsp; ACM Multimedia (ACM MM).<br>
		&emsp; AAAI Conference on Artificial Intelligence (AAAI).<br>
		&emsp; IEEE International Conference on Robotics and Automation (ICRA).<br>
		&emsp; IEEE International Conference on Intelligent Robots and Systems (IROS).<br>
		<!-- &emsp; SIGGRAPH. <br> -->
	</li>
	<li>Journal Reviewer:<br>
		&emsp; IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI).<br>
		&emsp; International Journal of Computer Vision (IJCV).<br>
		&emsp; IEEE Transactions on Image Processing (TIP).<br>
		&emsp; IEEE Transactions on Multimedia (TMM).<br>
		&emsp; IEEE Transactions on Circuits and Systems for Video Technology (TCSVT).<br>
		&emsp; IEEE Robotics and Automation Letters (RA-L).<br>
	</li>
</ul>

<h2>Honors & Awards</h2>
<table style="border-spacing:2px" width="100%">
<tbody>
	<tr><td>World’s Top 2% Scientist (Single Year), Stanford University and Elsevier</td><td>2024</td></tr>
</tbody>
</table>
<!-- 
<h2>Teaching</h2>
<ul>
	<li>Teaching:
		<table id="Teaching" border="0" width="100%">
			<tbody>
				<tr>
					<td style="width:80%">CSC3100 Data Structure</td><td>Spring</td><td>2023-2024</td>
				</tr>
				<tr>
					<td style="width:80%">CSC6051/MDS5112 Image Processing and Computer Vision</td><td>Fall</td><td>2024-2025</td>
				</tr>
				<tr>
					<td style="width:80%">CSC3100 Data Structure</td><td>Spring</td><td>2024-2025</td>
				</tr>
			</tbody>
		</table>
	</li>

	<li>Teaching Assistant:
		<table id="TeachingAssistant" border="0" width="100%">
			<tbody>
				<tr>
					<td style="width:80%">ENGG5104 Image Processing and Computer Vision</td><td>Spring</td><td>2020-2021</td>
				</tr>
				<tr>
					<td>ENGG1110 Problem Solving By Programming</td><td>Fall</td><td>2019-2020</td>
				</tr>
				<tr>
					<td>CSCI2100B Data Structure</td><td>Spring</td><td>2018-2019</td>
				</tr>
				<tr>
					<td>ENGG1110 Problem Solving By Programming</td><td>Fall</td><td>2018-2019</td>
				</tr>
				<tr>
					<td>ENGG1100 Introduction to Engineering Design</td><td>Spring</td><td>2017-2018</td>
				</tr>
				<tr>
					<td>CSCI1130 Introduction to Computing Using JAVA</td><td>Fall</td><td>2017-2018</td>
				</tr>
			</tbody>
		</table>
	</li>
</ul> -->

<!-- <div id="footer"> -->
	<!-- <div id="footer-text"></div>
	</div>
		<center>© Li Jiang | 2022</center>
	</div> -->

	<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-88615920-1', 'auto');
	ga('send', 'pageview');

	</script>
<!-- </div> -->

<div id="cm" style="display: none;">
	<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=EJGgXVNElphSoGp99mBvvA0EUD4cBLxcWb-YyZQBjro&cl=ffffff&w=a"></script>
</div>

</body>
</html>
